{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import csv\n",
    "import psycopg2 \n",
    "import json\n",
    "load_dotenv()\n",
    "\n",
    "URL_DB = os.environ.get(\"URL_DB\")\n",
    "CONN = psycopg2.connect(URL_DB)\n",
    "CURSOR = CONN.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: GROUP LOCATION BY COUNTRIES. \n",
    "# NOTE: WHERE IS LOCATION == NONE?\n",
    "# NOTE: WHERE IS DESCRIPTION == NONE?\n",
    "\n",
    "\n",
    "## TODO: NEED TO TRANSFROM COMMON TWO WORDS SUCH AS UNITED STATES INTO \"USA\"; \"NEW YORK\", \n",
    "\n",
    "## TODO: AS SOME LOCATIONS CONTAIN MORE THAN A WORD, IT SHOULD ADD THE NEXT WORD IF THE RESULT IS UNKNOWN, AND IF THEIR INDEX ARE THE SAME. ELSE FINALLY ASSING UNKNOWN AGAIN\n",
    "\n",
    "timestamp = \"2024-05-01 00:00:00.000000\"\n",
    "\n",
    "CURSOR.execute(\n",
    "\tf\"SELECT location FROM main_jobs  WHERE timestamp > '{timestamp}'\"\n",
    ")\n",
    "new_data = CURSOR.fetchall()\n",
    "\n",
    "df = pd.DataFrame(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(file_path: str) -> dict:\n",
    "\twith open(file_path, 'r') as file:\n",
    "\t\treturn json.load(file)\n",
    "\n",
    "def save_json_file(data: dict, file_path: str) -> None:\n",
    "\twith open(file_path, 'w') as file:\n",
    "\t\tjson.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the column name (there's only one)\n",
    "location = df.columns[0]\n",
    "\n",
    "# Get unique values\n",
    "#unique_values = df[location].str.strip().unique()\n",
    "\n",
    "df[location] = df[location].str.strip().str.split()\n",
    "\n",
    "df = df.explode(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>Arab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>Worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38544 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0        Remote\n",
       "0           USA\n",
       "0        Europe\n",
       "0      (remote)\n",
       "0        Remote\n",
       "...         ...\n",
       "7993       Arab\n",
       "7993   Emirates\n",
       "7994  Worldwide\n",
       "7995   Pakistan\n",
       "7996   Pakistan\n",
       "\n",
       "[38544 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0   location_tag\n",
      "0        Remote        Unknown\n",
      "0           USA  United States\n",
      "0        Europe         Europe\n",
      "0      (remote)        Unknown\n",
      "0        Remote        Unknown\n",
      "...         ...            ...\n",
      "7993       Arab        Unknown\n",
      "7993   Emirates        Unknown\n",
      "7994  Worldwide       Anywhere\n",
      "7995   Pakistan       Pakistan\n",
      "7996   Pakistan       Pakistan\n",
      "\n",
      "[38544 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## TODO: AS SOME LOCATIONS CONTAIN MORE THAN A WORD, IT SHOULD ADD THE NEXT WORD IF THE RESULT IS UNKNOWN, AND IF THEIR INDEX ARE THE SAME. ELSE FINALLY ASSING UNKNOWN AGAIN. MAKE A FUNCTION THAT CONCATENATES THE WORD THAT COULD NOT BE FOUND IN LOC.LOWER AND ADD ITS NEXT WORD ONLY IF THEIR INDEX ARE EQUAL. FOR EXAMPLE, THIS FUNCTION WOULD NOT MATCH THE WORD \"SAN\" BUT IF WE DO THIS, THEN THE CONCATENATED STRING WOULD BE \"SAN FRANCISCO\", WHICH SHOULD FIND ITS MATCH.\n",
    "\n",
    "def add_location_tags(df: pd.DataFrame, json_file_path: str) -> pd.DataFrame:\n",
    "\tlocation_data = load_json_file(json_file_path)\n",
    "\tdef find_location_tag(word: str) -> str:\n",
    "\t\tword_str = str(word)\n",
    "\t\tfor continent, countries in location_data.items():\n",
    "\t\t\tfor country in countries['Countries']:\n",
    "\t\t\t\tfor country_name, locations in country.items():\n",
    "\t\t\t\t\tfor loc in locations:\n",
    "\t\t\t\t\t\tif word_str.lower() in loc.lower():\n",
    "\t\t\t\t\t\t\treturn country_name\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\tif word_str.lower() == country_name.lower():\n",
    "\t\t\t\t\t\treturn country_name\n",
    "\t\t\tif word_str.lower() == continent.lower():\n",
    "\t\t\t\treturn continent\n",
    "\t\treturn \"Unknown\"\n",
    "\t\n",
    "\tdf['location_tag'] = df[0].apply(find_location_tag)\n",
    "\treturn df\n",
    "\n",
    "json_file_path = '/root/JobsCrawler/src/notebooks/all_locations_transformed.json'\n",
    "result_df = add_location_tags(df, json_file_path)\n",
    "print(result_df)\n",
    "\n",
    "result_df.to_csv(\"/root/JobsCrawler/src/notebooks/country_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation complete. Result saved to /root/JobsCrawler/src/notebooks/all_locations_transformed.json\n"
     ]
    }
   ],
   "source": [
    "def transform_data(input_data: dict[str, dict[str, list[dict[str, str | list[dict[str, str]]]]]]) -> dict[str, dict[str, list[dict[str, list[str]]]]]:\n",
    "\tresult = {}\n",
    "\tfor continent, data in input_data.items():\n",
    "\t\tresult[continent] = {\"Countries\": []}\n",
    "\t\tfor country in data[\"Countries\"]:\n",
    "\t\t\tcountry_name = country[\"country_name\"]\n",
    "\t\t\tcountry_code = country[\"country_code\"]\n",
    "\t\t\tcapital_english = country[\"capital_english\"]\n",
    "\t\t\t\n",
    "\t\t\tsubdivisions = []\n",
    "\t\t\tif isinstance(country[\"subdivisions\"], list):\n",
    "\t\t\t\tsubdivisions = [sub[\"subdivisions_name\"] for sub in country[\"subdivisions\"]]\n",
    "\t\t\telif country[\"subdivisions\"] != \"NaN\":\n",
    "\t\t\t\tsubdivisions = [country[\"subdivisions\"]]\n",
    "\t\t\t\n",
    "\t\t\ttransformed_country = {\n",
    "\t\t\t\tcountry_name: [country_code, capital_english] + subdivisions\n",
    "\t\t\t}\n",
    "\t\t\tresult[continent][\"Countries\"].append(transformed_country)\n",
    "\t\n",
    "\treturn result\n",
    "\n",
    "#Example usage:\n",
    "\n",
    "input_file = \"/root/JobsCrawler/src/notebooks/all_locations.json\"\n",
    "output_file = \"/root/JobsCrawler/src/notebooks/all_locations_transformed.json\"\n",
    "\n",
    "input_data = load_json_file(input_file)\n",
    "transformed_data = transform_data(input_data)\n",
    "save_json_file(transformed_data, output_file)\n",
    "\n",
    "print(\"Data transformation complete. Result saved to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(location_df):\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_country(location):\n",
    "\t# Remove 'Remote' and '(remote)' from the location string\n",
    "\tclean_location = re.sub(r'\\bRemote\\b|\\(remote\\)', '', location, flags=re.IGNORECASE).strip()\n",
    "\t\n",
    "\tfor country, keywords in COUNTRY_MAPPING.items():\n",
    "\t\tfor keyword in keywords:\n",
    "\t\t\tif keyword.lower() in clean_location.lower():\n",
    "\t\t\t\treturn country\n",
    "\t\n",
    "\t\n",
    "\treturn \"Other\"\n",
    "\n",
    "grouped_locations = {}\n",
    "\n",
    "for location in unique_values:\n",
    "\tcountry = get_country(location)\n",
    "\tif country not in grouped_locations:\n",
    "\t\tgrouped_locations[country] = []\n",
    "\tgrouped_locations[country].append(location)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/JobsCrawler/src/notebooks/countries.json\", mode=\"w+\") as file:\n",
    "\tjson.dump(grouped_locations, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
